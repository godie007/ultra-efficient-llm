#!/usr/bin/env python3
"""
Test final del modelo UltraEfficientLLM con dataset de acuapon√≠a optimizado
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from ultra_efficient_llm import UltraEfficientLLM

def cargar_dataset(ruta_archivo):
    """Carga el dataset desde un archivo"""
    try:
        with open(ruta_archivo, 'r', encoding='utf-8') as f:
            return f.read().strip().split('\n')
    except FileNotFoundError:
        print(f"‚ùå No se encontr√≥ el archivo: {ruta_archivo}")
        return []

def evaluar_respuesta_final(pregunta, respuesta):
    """Eval√∫a la calidad final de la respuesta"""
    score = 0
    
    # Respuestas esperadas exactas
    respuestas_exactas = {
        "¬øQu√© es la acuapon√≠a?": "La acuapon√≠a combina peces y plantas",
        "¬øQu√© peces puedo usar?": "Los peces m√°s comunes son tilapia y carpa",
        "¬øQu√© plantas crecen?": "Las plantas m√°s comunes son lechugas y hierbas",
        "¬øCu√°nta agua usa?": "Usa menos agua que la agricultura tradicional",
        "¬øEs org√°nica?": "S√≠, es org√°nica y no necesita fertilizantes qu√≠micos",
        "¬øC√≥mo funciona?": "Los peces producen desechos que las plantas usan como nutrientes",
        "¬øQu√© beneficios tiene?": "Es sostenible, eficiente y produce alimentos frescos",
        "¬øEs sostenible?": "S√≠, es sostenible y respetuoso con el medio ambiente"
    }
    
    respuesta_esperada = respuestas_exactas.get(pregunta, "")
    
    # Puntuaci√≥n por similitud con respuesta esperada
    if respuesta_esperada:
        palabras_esperadas = respuesta_esperada.lower().split()
        palabras_respuesta = respuesta.lower().split()
        
        # Contar palabras coincidentes
        coincidencias = sum(1 for palabra in palabras_esperadas if palabra in palabras_respuesta)
        if coincidencias >= len(palabras_esperadas) * 0.8:  # 80% de coincidencia
            score += 8
        elif coincidencias >= len(palabras_esperadas) * 0.6:  # 60% de coincidencia
            score += 6
        elif coincidencias >= len(palabras_esperadas) * 0.4:  # 40% de coincidencia
            score += 4
        elif coincidencias >= len(palabras_esperadas) * 0.2:  # 20% de coincidencia
            score += 2
    
    # Puntuaci√≥n por longitud apropiada
    if 10 <= len(respuesta) <= 100:
        score += 1
    
    # Penalizaci√≥n por repetici√≥n excesiva
    words = respuesta.split()
    if len(words) > 0:
        unique_words = len(set(words))
        repetition_ratio = unique_words / len(words)
        if repetition_ratio < 0.5:  # Mucha repetici√≥n
            score -= 2
        elif repetition_ratio > 0.8:  # Buena variedad
            score += 1
    
    # Penalizaci√≥n por comas excesivas
    comma_count = respuesta.count(',')
    if comma_count > len(respuesta) / 20:  # M√°s de 5% comas
        score -= 1
    
    return max(0, min(10, score))

def test_acuaponia_final():
    """Test final con dataset de acuapon√≠a optimizado"""
    print("üß™ TEST FINAL - MODELO ACUAPON√çA OPTIMIZADO")
    print("=" * 50)
    
    # Cargar dataset optimizado
    dataset = cargar_dataset('data/acuaponia_minimal.txt')
    if not dataset:
        print("‚ùå No se pudo cargar el dataset")
        return
    
    print(f"üìö Dataset cargado: {len(dataset)} l√≠neas")
    
    # Crear modelo con par√°metros optimizados
    model = UltraEfficientLLM(
        max_pattern_length=6,  # Patrones cortos para simplicidad
        min_frequency=1,
        max_patterns=6000
    )
    
    print("üîÑ Entrenando modelo...")
    model.train(dataset)
    print(f"‚úÖ Modelo entrenado con {len(model.patterns)} patrones")
    
    # Preguntas de prueba
    questions = [
        "¬øQu√© es la acuapon√≠a?",
        "¬øQu√© peces puedo usar?",
        "¬øQu√© plantas crecen?",
        "¬øCu√°nta agua usa?",
        "¬øEs org√°nica?",
        "¬øC√≥mo funciona?",
        "¬øQu√© beneficios tiene?",
        "¬øEs sostenible?"
    ]
    
    print("\nüîç PROBANDO RESPUESTAS FINALES:")
    print("-" * 30)
    
    total_score = 0
    respuestas_exitosas = 0
    
    for i, question in enumerate(questions, 1):
        print(f"\n{i}. Pregunta: {question}")
        
        # Generar respuesta con temperatura muy baja para mayor determinismo
        response = model.generate(question, max_length=25, temperature=0.1)
        print(f"   Respuesta: {response}")
        
        # Evaluar respuesta
        score = evaluar_respuesta_final(question, response)
        total_score += score
        if score >= 6:
            respuestas_exitosas += 1
        print(f"   Calidad: {score}/10")
        
        # Verificar si contiene elementos de archivo
        file_elements = ['txt', 'py', 'md', 'data', 'test', 'main', 'config', 'utils', 'models', 'src']
        has_file_elements = any(elem in response.lower() for elem in file_elements)
        
        if has_file_elements:
            print(f"   ‚ö†Ô∏è  CONTIENE ELEMENTOS DE ARCHIVO!")
        else:
            print(f"   ‚úÖ SIN ELEMENTOS DE ARCHIVO")
    
    average_score = total_score / len(questions)
    success_rate = respuestas_exitosas / len(questions) * 100
    
    print(f"\nüìä RESULTADOS FINALES:")
    print(f"   Puntuaci√≥n promedio: {average_score:.1f}/10")
    print(f"   Tasa de √©xito: {success_rate:.1f}%")
    
    if average_score >= 7 and success_rate >= 75:
        print("üéâ ¬°EXCELENTE! El modelo est√° funcionando correctamente")
        print("‚úÖ Los filtros eliminaron elementos de archivo")
        print("‚úÖ Las respuestas son coherentes y directas")
    elif average_score >= 5 and success_rate >= 50:
        print("üëç BUENO: El modelo est√° mejorando significativamente")
        print("‚úÖ Los filtros funcionan correctamente")
        print("‚ö†Ô∏è  Las respuestas necesitan mejorar en coherencia")
    else:
        print("‚ö†Ô∏è  NECESITA MEJORAS: El modelo a√∫n no genera respuestas √≥ptimas")
        print("‚úÖ Los filtros funcionan correctamente")
        print("‚ùå Las respuestas necesitan mejorar en coherencia y precisi√≥n")

def test_prompts_simples():
    """Test con prompts simples"""
    print("\nüîç TEST - PROMPTS SIMPLES:")
    print("-" * 30)
    
    dataset = cargar_dataset('data/acuaponia_minimal.txt')
    if not dataset:
        return
    
    model = UltraEfficientLLM(max_pattern_length=6, min_frequency=1, max_patterns=6000)
    model.train(dataset)
    
    simple_prompts = ["acuapon√≠a", "peces", "plantas", "agua", "org√°nico", "sostenible"]
    
    for prompt in simple_prompts:
        response = model.generate(prompt, max_length=15, temperature=0.2)
        print(f"'{prompt}' ‚Üí {response}")
        
        # Verificar calidad b√°sica
        if len(response.split()) > 2 and response.count(',') < len(response) / 25:
            print(f"   ‚úÖ Respuesta coherente")
        else:
            print(f"   ‚ö†Ô∏è  Respuesta necesita mejorar")

if __name__ == "__main__":
    test_acuaponia_final()
    test_prompts_simples() 