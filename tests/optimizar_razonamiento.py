#!/usr/bin/env python3
"""
ğŸ”§ OPTIMIZACIÃ“N DE PARÃMETROS PARA MEJORAR RAZONAMIENTO
=======================================================

Este script prueba diferentes configuraciones del modelo para optimizar el razonamiento.
"""

import sys
import os
sys.path.append('src')

from ultra_efficient_llm import UltraEfficientLLM
import time

def cargar_dataset(ruta_archivo):
    """Cargar dataset desde archivo"""
    try:
        with open(ruta_archivo, 'r', encoding='utf-8') as f:
            return [linea.strip() for linea in f if linea.strip()]
    except FileNotFoundError:
        print(f"âŒ No se encontrÃ³ el archivo: {ruta_archivo}")
        return None

def evaluar_razonamiento_simple(respuesta, palabras_clave):
    """EvaluaciÃ³n simple de razonamiento"""
    puntuacion = 0
    for palabra in palabras_clave:
        if palabra.lower() in respuesta.lower():
            puntuacion += 1
    return puntuacion / len(palabras_clave) * 100

def test_configuracion(model, config_name):
    """Probar una configuraciÃ³n especÃ­fica"""
    print(f"\nğŸ§ª Probando configuraciÃ³n: {config_name}")
    print("=" * 50)
    
    preguntas_test = [
        {
            "pregunta": "Â¿Por quÃ© las plantas crecen bien en acuaponÃ­a?",
            "palabras_clave": ["nutrientes", "desechos", "peces", "naturales"]
        },
        {
            "pregunta": "Â¿QuÃ© pasa si no hay peces en el sistema?",
            "palabras_clave": ["nutrientes", "plantas", "morir", "sistema"]
        },
        {
            "pregunta": "Si las plantas estÃ¡n amarillas, Â¿quÃ© puede estar pasando?",
            "palabras_clave": ["nutrientes", "deficiencia", "problema", "causa"]
        }
    ]
    
    puntuaciones = []
    
    for test in preguntas_test:
        respuesta = model.generate(test['pregunta'], max_length=40, temperature=0.3)
        puntuacion = evaluar_razonamiento_simple(respuesta, test['palabras_clave'])
        puntuaciones.append(puntuacion)
        
        print(f"â“ {test['pregunta']}")
        print(f"ğŸ¤– {respuesta}")
        print(f"ğŸ“Š PuntuaciÃ³n: {puntuacion:.1f}%")
    
    promedio = sum(puntuaciones) / len(puntuaciones)
    print(f"\nğŸ“ˆ PuntuaciÃ³n promedio: {promedio:.1f}%")
    
    return promedio

def main():
    """FunciÃ³n principal"""
    print("ğŸ”§ OPTIMIZACIÃ“N DE PARÃMETROS PARA RAZONAMIENTO")
    print("=" * 60)
    
    # Cargar dataset mejorado
    dataset = cargar_dataset('data/acuaponia_razonamiento.txt')
    if not dataset:
        print("âŒ No se pudo cargar el dataset mejorado")
        return
    
    print(f"ğŸ“š Dataset cargado: {len(dataset)} lÃ­neas")
    
    # Configuraciones a probar
    configuraciones = [
        {
            "name": "ConfiguraciÃ³n BÃ¡sica",
            "max_pattern_length": 6,
            "min_frequency": 1,
            "max_patterns": 6000
        },
        {
            "name": "Patrones MÃ¡s Largos",
            "max_pattern_length": 8,
            "min_frequency": 1,
            "max_patterns": 8000
        },
        {
            "name": "MÃ¡s Patrones",
            "max_pattern_length": 6,
            "min_frequency": 1,
            "max_patterns": 10000
        },
        {
            "name": "Frecuencia MÃ­nima Mayor",
            "max_pattern_length": 6,
            "min_frequency": 2,
            "max_patterns": 6000
        },
        {
            "name": "ConfiguraciÃ³n Avanzada",
            "max_pattern_length": 8,
            "min_frequency": 1,
            "max_patterns": 12000
        }
    ]
    
    resultados = {}
    
    for config in configuraciones:
        print(f"\nğŸ”„ Entrenando modelo con {config['name']}...")
        
        # Crear modelo con configuraciÃ³n especÃ­fica
        model = UltraEfficientLLM(
            max_pattern_length=config['max_pattern_length'],
            min_frequency=config['min_frequency'],
            max_patterns=config['max_patterns']
        )
        
        # Entrenar modelo
        start_time = time.time()
        model.train(dataset)
        training_time = time.time() - start_time
        
        print(f"âœ… Entrenamiento completado en {training_time:.2f} segundos")
        
        # Probar configuraciÃ³n
        puntuacion = test_configuracion(model, config['name'])
        resultados[config['name']] = {
            'puntuacion': puntuacion,
            'tiempo_entrenamiento': training_time,
            'config': config
        }
    
    # Mostrar resultados finales
    print("\n" + "="*60)
    print("ğŸ“Š RESULTADOS DE OPTIMIZACIÃ“N")
    print("="*60)
    
    # Ordenar por puntuaciÃ³n
    resultados_ordenados = sorted(resultados.items(), key=lambda x: x[1]['puntuacion'], reverse=True)
    
    for i, (nombre, datos) in enumerate(resultados_ordenados, 1):
        print(f"\n{i}. {nombre}")
        print(f"   ğŸ“ˆ PuntuaciÃ³n: {datos['puntuacion']:.1f}%")
        print(f"   â±ï¸  Tiempo: {datos['tiempo_entrenamiento']:.2f}s")
        print(f"   âš™ï¸  Config: {datos['config']}")
    
    # Mejor configuraciÃ³n
    mejor_config = resultados_ordenados[0]
    print(f"\nğŸ† MEJOR CONFIGURACIÃ“N: {mejor_config[0]}")
    print(f"   PuntuaciÃ³n: {mejor_config[1]['puntuacion']:.1f}%")
    
    # Recomendaciones
    print(f"\nğŸ’¡ RECOMENDACIONES:")
    print(f"   1. Usar {mejor_config[0]} para mejor razonamiento")
    print(f"   2. El dataset mejorado tiene {len(dataset)} lÃ­neas vs 72 originales")
    print(f"   3. Incluye ejemplos de razonamiento causal, inferencial y comparativo")
    
    # Guardar mejor modelo
    print(f"\nğŸ’¾ Guardando mejor modelo...")
    mejor_modelo = UltraEfficientLLM(
        max_pattern_length=mejor_config[1]['config']['max_pattern_length'],
        min_frequency=mejor_config[1]['config']['min_frequency'],
        max_patterns=mejor_config[1]['config']['max_patterns']
    )
    mejor_modelo.train(dataset)
    mejor_modelo.save_model("models/mejor_razonamiento.pkl")
    print(f"âœ… Modelo guardado como 'mejor_razonamiento.pkl'")

if __name__ == "__main__":
    main() 